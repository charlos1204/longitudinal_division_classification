{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Efficient detection of longitudinal bacteria fission using transfer learning in Deep Neural Networks\n",
    "# <center> Supplemental Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code for longitudinal division classification\n",
    "\n",
    "#### Requirements:\n",
    " * GPU\n",
    " * Nvidia driver\n",
    " * cuda version > 10\n",
    " * torch\n",
    " * torchvision\n",
    " * sklearn\n",
    " * numpy\n",
    " * pandas\n",
    "\n",
    "#### Folders\n",
    " * data: contains all image samples in the folders train, validation and test. \n",
    " * model: where the trained model will be saved\n",
    " \n",
    "#### train_functions_sgd.py code contains all functions that are called in the main function. Do not remove or delete this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import train_functions_sgd as trnfn\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for making the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtraining():\n",
    "    print('processing data')\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'data/'\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                                  shuffle=True, num_workers=8)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Device: {device} / Dataset_size: {dataset_sizes}')\n",
    "\n",
    "    # prepare for training\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    model_ft = trnfn.train_model(model_ft, criterion, optimizer_ft, \n",
    "                                 exp_lr_scheduler, dataloaders, \n",
    "                                 dataset_sizes, device, num_epochs=25)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model_ft.state_dict(), \"model/trained_net_sgd.pth\")\n",
    "  \n",
    "    y_true, y_pred = trnfn.test_model(model_ft, criterion, device, dataloaders, dataset_sizes)\n",
    "    y_pred = y_pred + 1\n",
    "    y_pred = y_pred % 2\n",
    "\n",
    "    print(\"accuracy score: \",accuracy_score(y_true, y_pred),\"\\n\")\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred),\"\\n\")\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtraining()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
