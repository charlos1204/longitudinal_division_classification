{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Efficient detection of longitudinal bacteria fission using transfer learning in Deep Neural Networks\n",
    "# <center> Supplemental Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most rod-shaped bacteria divide perpendicularly (along the narrow axis). Some, however, divide longitudinally (along the long axis). Few species are known to do so. Here we create a model of longitudinal divison that can help experimentalist researches to classify such images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code for longitudinal division classification\n",
    "\n",
    "#### Requirements:\n",
    " * GPU\n",
    " * Nvidia driver\n",
    " * cuda version > 10\n",
    " * cython\n",
    " * opencv-python\n",
    " * tqdm\n",
    " * torchsummary\n",
    " * matplotlib\n",
    " * pandas\n",
    " * scipy\n",
    " * joblib\n",
    " * scikit-learn\n",
    " * jupyterlab\n",
    " * torch\n",
    " * torchvision\n",
    " * torchaudio\n",
    " * numpy\n",
    "\n",
    "#### Folders\n",
    " * data: contains all image samples in the folders train, validation and test. \n",
    " * model: where the trained model will be saved\n",
    " \n",
    "#### train_functions_sgd.py code contains all functions that are called in the main function. Do not remove or delete this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code for training a pretrained resnet18 network to classify microscopy images of longitudinal division bacteria.\n",
    "\n",
    "The code is based on transfer learning for computer vision. The original code can be [here](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n",
    "* runtraining() main function to perform the training of a binary classifier (0,1)\n",
    "* data: Contains the folders train, val and test\n",
    "* train, val, test: Are folders with image samples to train the model.\n",
    "* model: Is the folder where the trained model will be save\n",
    "\n",
    "========== How to run in terminal ==========\n",
    "\n",
    "Copy and paste the code into a file called train_model, then run in a terminal:\n",
    "\n",
    "`python train_model.py`\n",
    "\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import train_functions_sgd as trnfn\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for making the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtraining():\n",
    "    print('processing data')\n",
    "    \n",
    "    # data transformations to prepare the images for training\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = 'data/'\n",
    "\n",
    "    # image loader on batch of 8 images\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=8)\n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "    \n",
    "    # extract the classes label: 0 and 1\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    # setting up the device to train in CPU or GPU\n",
    "    # if torch doesn't find a GPU available it will run on the CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Device: {device} / Dataset_size: {dataset_sizes}')\n",
    "\n",
    "    # prepare for training\n",
    "    # setting a pretrained resnet18.\n",
    "    # nn.Lienear(in_features, out_features): \n",
    "    # applies a linear transformation to the incoming data (features) to out features\n",
    "    # the features are extracted from the pretrained resnet18 into 2 features. \n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    # Setting up the type of loss function to optimize the model during training.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setting up the optimizer function.\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    \n",
    "    # training function\n",
    "    # train_model:\n",
    "    #             model_ft: defined model (Resnet18)\n",
    "    #             criterion: cross entropy loss function\n",
    "    #             optimizer_ft: optimization algorithm Stochastic Gradient Descent (SGD)\n",
    "    #             exp_lr_scheduler: decay LR by a factor\n",
    "    #             dataloaders: batch of images, 8 images per batch\n",
    "    #             dataset_sizes: size of train and val samples\n",
    "    #             device: GPU or CPU\n",
    "    #             num_epochs: number of epochs to train in the data\n",
    "    model_ft = trnfn.train_model(model_ft, criterion, optimizer_ft, \n",
    "                                 exp_lr_scheduler, dataloaders, \n",
    "                                 dataset_sizes, device, num_epochs=25)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model_ft.state_dict(), \"model/trained_net_sgd.pth\")\n",
    "  \n",
    "    y_true, y_pred = trnfn.test_model(model_ft, criterion, device, dataloaders, dataset_sizes)\n",
    "    y_pred = y_pred\n",
    "    y_pred = y_pred\n",
    "\n",
    "    print(\"accuracy score: \",\"%.6f\" % accuracy_score(y_true, y_pred),\"\\n\")\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred),\"\\n\")\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "setting a random seed for reproducibility\n",
    "however, Pytorch state:\n",
    "\n",
    "\"Completely reproducible results are not guaranteed across PyTorch releases, \n",
    "individual commits, or different platforms. Furthermore, results may not be \n",
    "reproducible between CPU and GPU executions, even when using identical seeds.\"\n",
    "\n",
    "\"\"\"\"\n",
    "np.random.seed(1234)\n",
    "\n",
    "runtraining()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
